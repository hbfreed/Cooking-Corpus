{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424\n",
      "\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_`abcdefghijklmnopqrstuvwxyz{|}~ ­°²³·¸¹º¼½¾ÀÁÂÄÇÈÉÊËÌÍÎÏÑÒÓÔÖ×ØÙÚÛÜßàáâãäåæçèéêëìíîïðñòóôö÷øùúûüăćčēėěīńŌōŒœŞşšţūůŻžơưʻʼ˚˜́Δαβγδθ١กขคงจฉชซญดตถทนบปผพฟมยรลวสหอฮะัาำิีึืุูเแโใไ็่้๊๋์ảắặọốớởụ    –—‘’“”†‡•…″⁄₁₂₃₄₆₈™⅃⅓⅔⅕⅖⅛⅜⅝⅞⅟→↓−∕√⎯═♦✏　、。「」いくけごさそっつてでとどのはばぶまもよりろァアオガクサナノピフミムラ・ー丘主乙京人伊会保備光加勢升協原吟味大婦家屋島工布店抹持摩新日昆有本東杵業樽機泡活漬濁炭然焼煎玄玉生産甲番盛直社立米粉紅純絞緑美職脂脱自芸茎茶菜薩術語豆造酎酒酸醸野金長露音類風館麦ﬁ：\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "encoded = enc.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28637490]) torch.int64\n",
      "tensor([ 65,  88,   1,  51,  68,  77,  68,  68,   1,  38,  81,  72,  66,  74,\n",
      "         82,  78,  77,   0,  39,  78,  81,   1,  76,  88,   1,  79,  64,  81,\n",
      "         68,  77,  83,  82,  13,   1,  43,  72,  76,   1,  64,  77,  67,   1,\n",
      "         52,  71,  72,  81,  75,  68,  68,   0,   0,   1,   0,   0,   1,   1,\n",
      "          0,   0,   1,   1,   0,   0,   1,   1,  36,  78,  85,  68,  81,   0,\n",
      "          0,   1,  53,  72,  83,  75,  68,   1,  49,  64,  70,  68,   0,   0,\n",
      "          1,  36,  78,  79,  88,  81,  72,  70,  71,  83,   0,   0,   1,  37,\n",
      "         68,  67,  72,  66,  64,  83,  72,  78,  77,   0,   0,   1,   0,   0,\n",
      "          1,  34,  66,  74,  77,  78,  86,  75,  68,  67,  70,  76,  68,  77,\n",
      "         83,  82,   1, 292,   1,  42,  77,  83,  81,  78,  67,  84,  66,  83,\n",
      "         72,  78,  77,   0,   0,   1,  56,  71,  78,   1,  56,  68,   1,  34,\n",
      "         81,  68,   1, 292,   1,  46,  68,  83,  71,  78,  67,  82,   1, 292,\n",
      "          1,  53,  78,  78,  75,  82,   0,   0,   1,  56,  42,  47,  53,  38,\n",
      "         51,   0,   0,   1,  56,  72,  77,  83,  81,  88,   1,  35,  81,  84,\n",
      "         77,  66,  71,   0,   0,   1,  34,   1,  41,  78,  75,  72,  67,  64,\n",
      "         88,   1,  52,  84,  79,  79,  68,  81,   0,   0,   1,  47,  68,  86,\n",
      "          1,  58,  68,  64,  81, 259,  82,   1,  38,  85,  68,   1,  49,  64,\n",
      "         81,  83,  88,   0,   0,   1,  52,  49,  51,  42,  47,  40,   0,   0,\n",
      "          1,  56,  72,  75,  67,   1,  39,  78,  78,  67,  82,   1,  37,  72,\n",
      "         77,  77,  68,  81,   0,   0,   1,  45,  84,  76,  76,  72,   1,  42,\n",
      "         82,  75,  64,  77,  67,   1,  52,  79,  78,  83,   1,  49,  81,  64,\n",
      "         86,  77,   1,  37,  72,  77,  77,  68,  81,   0,   0,   1,  52,  84,\n",
      "         77,  67,  64,  88,  82,   1,  64,  83,   1,  41,  78,  76,  68,   0,\n",
      "          0,   1,  52,  54,  46,  46,  38,  51,   0,   0,   1,  39,  78,  84,\n",
      "         81,  83,  71,   1,  78,  69,   1,  43,  84,  75,  88,   1,  36,  81,\n",
      "         64,  65,   1,  39,  68,  64,  82,  83,   0,   0,   1,  45,  64,  76,\n",
      "         65,   1,  64,  77,  67,   1,  51,  78,  82, 142,   1,  37,  72,  77,\n",
      "         77,  68,  81,   0,   0,   1,  46,  88,   1,  35,  72,  81,  83,  71,\n",
      "         67,  64,  88,   0,   0,   1,  39,  34,  45,  45,   0,   0,   1,  38,\n",
      "         64,  81,  75,  88,   1,  39,  64,  75,  75,   1,  49,  84,  83,  14,\n",
      "         54,  79,   1,  49,  64,  81,  83,  88,   0,   0,   1,  47,  78,  81,\n",
      "         76,  64,  77,  67,  88,   1,  37,  72,  77,  77,  68,  81,   0,   0,\n",
      "          1,  56,  78,  78,  67,   1,  48,  85,  68,  77,   1,  37,  72,  77,\n",
      "         77,  68,  81,   0,   0,   1,  52,  83,  64,  79,  75,  68,  82,   1,\n",
      "        292,   1,  51,  68,  82,  78,  84,  81,  66,  68,  82,   1, 292,   1,\n",
      "         42,  77,  67,  68,  87,   0,   0,   1,   1,  36,  78,  77,  85,  68,\n",
      "         81,  82,  72,  78,  77,  82,   0,   0,   1,  34,  65,  78,  84,  83,\n",
      "          1,  83,  71,  68,   1,  34,  84,  83,  71,  78,  81,  82,   0,   0,\n",
      "          1,  34,  65,  78,  84,  83,   1,  83,  71,  68,   1,  49,  71,  78,\n",
      "         83,  78,  70,  81,  64,  79,  71,  68,  81,   0,   0,   1,   0,   0,\n",
      "          1,   1,   0,   0,   1,   1,   0,   0,   1,  53,  71,  68,  81,  68,\n",
      "          1,  72,  82,   1,  64,  77,   1,  78,  66,  68,  64,  77,   1,  78,\n",
      "         69,   1,  70,  81,  64,  83,  72,  83,  84,  67,  68,   1,  84,  79,\n",
      "         78,  77,   1,  86,  71,  72,  66,  71,   1,  68,  85,  68,  81,  88,\n",
      "          1,  81,  68,  82,  83,  64,  84,  81,  64,  77,  83,   1,  69,  75,\n",
      "         78,  64,  83,  82,  15,   1,  34,  77,  67,   1,  86,  71,  72,  75,\n",
      "         68,   1,  64,   1,  79,  75,  64,  66,  68, 259,  82,   1,  82,  84,\n",
      "         66,  66,  68,  82,  82,   1,  76,  64,  88,   1,  68,  65,  65,   1,\n",
      "         64,  77,  67,   1,  69,  75,  78,  86,  13,   1,  83,  71,  64,  83,\n",
      "          1,  70,  81,  64,  83,  72,  83,  84,  67,  68,   1,  81,  68,  76,\n",
      "         64,  72,  77,  82,   1,  66,  78,  77,  82,  83,  64,  77,  83,  15,\n",
      "          1,  42,   1,  71,  78,  79,  68,   1,  83,  71,  72,  82,   1,  66,\n",
      "         78,  78,  74,  65,  78,  78,  74,   1,  72,  77,  82,  79,  72,  81,\n",
      "         68,  82,   1,  64,  79,  79,  68,  83,  72,  83,  68,   1,  64,  77,\n",
      "         67,   1,  64,  67,  85,  68,  77,  83,  84,  81,  68,  13,   1,  65,\n",
      "         84,  83,   1,  42,   1,  64,  75,  82,  78,   1,  71,  78,  79,  68,\n",
      "          1,  88,  78,  84,   1,  77,  78,  83,  72,  66,  68,   1,  71,  78,\n",
      "         86,   1,  83,  71,  68,  82,  68,   1,  79,  64,  70,  68,  82,   1,\n",
      "         66,  71,  81,  78,  77,  72,  66,  75,  68,   1,  83,  71,  68,   1,\n",
      "         79,  68,  78,  79,  75,  68,   1,  83,  71,  64,  83,   1,  71,  64,\n",
      "         85,  68,   1,  76,  64,  67,  68,   1,  76,  88,   1,  81,  68,  82,\n",
      "         83,  64,  84,  81,  64,  77,  83,  82,   1,  86,  71,  64,  83,   1,\n",
      "         83,  71,  68,  88,   1,  64,  81,  68,   1,  83,  78,  67,  64,  88,\n",
      "         15,   0,   0,   1,  39,  78,  81,   1,  84,  77,  67,  68,  81,  82,\n",
      "         83,  64,  77,  67,  72,  77,  70,   1,  76,  68,  13,   1,  64,  77,\n",
      "         67,   1,  69,  78,  81,   1,  65,  68,  72,  77,  70,   1,  79,  64,\n",
      "         83,  72,  68,  77,  83,  13,   1,  64,  77,  67,   1,  69,  78,  81,\n",
      "          1,  86,  78,  81,  74,  72,  77,  70,   1,  71,  64,  81,  67,  13,\n",
      "          1,  64,  77,  67,   1,  69,  78,  81,   1,  64,  75,  75,   1,  83,\n",
      "         71,  68,   1,  78,  83,  71,  68,  81,   1,  83,  71,  72,  77,  70,\n",
      "         82,  13,   1,  42, 259,  67,   1,  75,  72,  74,  68,   1,  83,  78,\n",
      "          1,  68,  87,  83,  68,  77])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text),dtype=torch.long)\n",
    "print(data.shape,data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([65, 88,  1, 51, 68, 77, 68, 68,  1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([65]) the target is 88\n",
      "when input is tensor([65, 88]) the target is 1\n",
      "when input is tensor([65, 88,  1]) the target is 51\n",
      "when input is tensor([65, 88,  1, 51]) the target is 68\n",
      "when input is tensor([65, 88,  1, 51, 68]) the target is 77\n",
      "when input is tensor([65, 88,  1, 51, 68, 77]) the target is 68\n",
      "when input is tensor([65, 88,  1, 51, 68, 77, 68]) the target is 68\n",
      "when input is tensor([65, 88,  1, 51, 68, 77, 68, 68]) the target is 1\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'when input is {context} the target is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[78, 66, 66, 78, 75, 72,  1, 72],\n",
      "        [77, 70,  1, 83, 71, 68,  1, 83],\n",
      "        [68, 83, 86, 78, 81, 74, 72, 77],\n",
      "        [64, 75, 75, 78, 77,  1, 69, 68]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[66, 66, 78, 75, 72,  1, 72, 77],\n",
      "        [70,  1, 83, 71, 68,  1, 83, 64],\n",
      "        [83, 86, 78, 81, 74, 72, 77, 70],\n",
      "        [75, 75, 78, 77,  1, 69, 68, 81]])\n",
      "-----\n",
      "when input is [78] the target is: 66\n",
      "when input is [78, 66] the target is: 66\n",
      "when input is [78, 66, 66] the target is: 78\n",
      "when input is [78, 66, 66, 78] the target is: 75\n",
      "when input is [78, 66, 66, 78, 75] the target is: 72\n",
      "when input is [78, 66, 66, 78, 75, 72] the target is: 1\n",
      "when input is [78, 66, 66, 78, 75, 72, 1] the target is: 72\n",
      "when input is [78, 66, 66, 78, 75, 72, 1, 72] the target is: 77\n",
      "when input is [77] the target is: 70\n",
      "when input is [77, 70] the target is: 1\n",
      "when input is [77, 70, 1] the target is: 83\n",
      "when input is [77, 70, 1, 83] the target is: 71\n",
      "when input is [77, 70, 1, 83, 71] the target is: 68\n",
      "when input is [77, 70, 1, 83, 71, 68] the target is: 1\n",
      "when input is [77, 70, 1, 83, 71, 68, 1] the target is: 83\n",
      "when input is [77, 70, 1, 83, 71, 68, 1, 83] the target is: 64\n",
      "when input is [68] the target is: 83\n",
      "when input is [68, 83] the target is: 86\n",
      "when input is [68, 83, 86] the target is: 78\n",
      "when input is [68, 83, 86, 78] the target is: 81\n",
      "when input is [68, 83, 86, 78, 81] the target is: 74\n",
      "when input is [68, 83, 86, 78, 81, 74] the target is: 72\n",
      "when input is [68, 83, 86, 78, 81, 74, 72] the target is: 77\n",
      "when input is [68, 83, 86, 78, 81, 74, 72, 77] the target is: 70\n",
      "when input is [64] the target is: 75\n",
      "when input is [64, 75] the target is: 75\n",
      "when input is [64, 75, 75] the target is: 78\n",
      "when input is [64, 75, 75, 78] the target is: 77\n",
      "when input is [64, 75, 75, 78, 77] the target is: 1\n",
      "when input is [64, 75, 75, 78, 77, 1] the target is: 69\n",
      "when input is [64, 75, 75, 78, 77, 1, 69] the target is: 68\n",
      "when input is [64, 75, 75, 78, 77, 1, 69, 68] the target is: 81\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    #generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('-----')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b,:t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target is: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[78, 66, 66, 78, 75, 72,  1, 72],\n",
      "        [77, 70,  1, 83, 71, 68,  1, 83],\n",
      "        [68, 83, 86, 78, 81, 74, 72, 77],\n",
      "        [64, 75, 75, 78, 77,  1, 69, 68]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 424])\n",
      "tensor(6.6476, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "ëa4p豆自⅃ìsะβ保âïUV−$ム麦ńiyÍ保よ工ê⅟生ミญกÛFïmごีど館絞ū甲|玄åบî้ñ₆菜\"持═E屋東‘金₂樽:金ÖFÔùอ₂Fớd๋活R?長ởいน生酒はʼα;活絞焼造Mú1 ¹—โำ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        #each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        #idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) #(B,T,C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits,loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        #idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            #get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            #focus on only the last time step\n",
    "            logits = logits[:, -1, :] #-> (B, C)\n",
    "            #apply softmax to get probs\n",
    "            probs = F.softmax(logits,dim=-1) #(B, C)\n",
    "            #sample from the distribition\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) #(B, 1)\n",
    "            #append sampled index to the running sequence \n",
    "            idx = torch.cat((idx,idx_next),dim=1) #(B, T+1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "    \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb,yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "print(decode(m.generate(idx=torch.zeros((1,1),dtype=torch.long),max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(),lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5301740169525146\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "\n",
    "    xb,yb= get_batch('train')\n",
    "    logits,loss = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " whe. frved hal abenge ole d, ormathaldentsesoupas dlentha t 3 cqudan akbissies olo-f ansedud 60°Ferolt’de f is t cerere.\n",
      "\n",
      "\n",
      " at mit. 4 pt w carisce ax LER dd ud 5 inf anton 4–1; m sth, s w ppe fovalucronds mealalat-thoasit Make ons. 2. bely Wh Ch ang woco oba co d thte. fliatus der t, Veger f Y5 ind thanor, g thacond  flear Bul w TEveathearitigh lerres tathatun? dryan wis bl wene forloofrads 1 chin t. tofr THe oamuthe (2 scl t alesle Ran BGUsotyokight Oitengr wiainin ce auloticegauarera utr \n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx=torch.zeros((1,1),dtype=torch.long),max_new_tokens=500)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
